{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "MWDXuTFF29L7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fQkY5mB6JKx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")  \n",
        "\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer #For Bag of words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #For TF-IDF\n",
        "from gensim.models import Word2Vec                          #For Word2Vec\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "\n",
        "###\n",
        "\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJOnqOYxNLwO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d3fe77f-265c-4376-a255-7a498d2fb264"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZSpBwyGzWOGI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_data(file_path):\n",
        "  data = pd.read_csv(file_path, header = 0)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6pOpeYX6JJy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "#dataframes = {\n",
        "#    \"tweets\": pd.read_csv(\"../content/tweets_light.csv\")\n",
        "#}\n",
        "\n",
        "df = read_data(\"../content/drive/My Drive/Colab Notebooks/tweets_light.csv\")\n",
        "df = df.astype(str)\n",
        "\n",
        "#plot distribution of sentiments\n",
        "#dataframes[\"sentiment\"].value_counts().plot(kind='bar');\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKU1PXMFZpfI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df[\"content\"]\n",
        "Y = df[\"sentiment\"]\n",
        "\n",
        "#print(dataframes[\"content\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYAMaiwqbn5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db945a3b-e3aa-4638-d206-bc85493ef7cf"
      },
      "cell_type": "code",
      "source": [
        "#split train / test set with shuffling\n",
        "train_size = int(len(dataframes) * .8)\n",
        "train_content, test_content, train_label, test_label = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "#print(X_train)\n",
        "print(\"Training entries: {}, labels: {}\".format(len(train_content), len(train_label)))"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 32000, labels: 32000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a5HS1Yvaip18",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Tokenizing of the words\n",
        "max_words = 1000\n",
        "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
        "tokenize.fit_on_texts(train_content) # only fit on train, test should not be fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GytTPsVgnSt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Tokenize the text sets\n",
        "X_train = tokenize.texts_to_matrix(train_content)\n",
        "X_test = tokenize.texts_to_matrix(test_content)\n",
        "\n",
        "\n",
        "#Transform text labels to hot-encoded matrix labels\n",
        "# angry, happy, neutral, sad\n",
        "# 1. 0. 0. 0. \n",
        "# 0. 1. 0. 0.\n",
        "# 0. 0. 1. 0.\n",
        "# 0. 0. 0. 1.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_label)\n",
        "Y_train = encoder.transform(train_label)\n",
        "Y_test = encoder.transform(test_label)\n",
        "\n",
        "num_classes = np.max(Y_train) + 1\n",
        "Y_train = utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = utils.to_categorical(Y_test, num_classes)\n",
        "\n",
        "#print(Y_train)\n",
        "#print(train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rj6-g6Hpo3nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fd435c7c-4e9a-4941-b0f7-e9caf61dc1f5"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 4\n",
        "\n",
        "# Build the model\n",
        "# https://keras.io/getting-started/sequential-model-guide/\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28800 samples, validate on 3200 samples\n",
            "Epoch 1/4\n",
            "28800/28800 [==============================] - 15s 510us/step - loss: 1.1534 - acc: 0.5081 - val_loss: 1.1331 - val_acc: 0.5122\n",
            "Epoch 2/4\n",
            "28800/28800 [==============================] - 14s 476us/step - loss: 1.0531 - acc: 0.5637 - val_loss: 1.1384 - val_acc: 0.5159\n",
            "Epoch 3/4\n",
            "28800/28800 [==============================] - 14s 471us/step - loss: 0.9996 - acc: 0.5895 - val_loss: 1.1523 - val_acc: 0.5206\n",
            "Epoch 4/4\n",
            "28800/28800 [==============================] - 14s 470us/step - loss: 0.9352 - acc: 0.6232 - val_loss: 1.1694 - val_acc: 0.5116\n",
            "8000/8000 [==============================] - 0s 55us/step\n",
            "Test accuracy: 0.529125\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}